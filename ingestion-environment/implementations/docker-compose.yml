services:
  vernemq:
    image: vernemq/vernemq:latest
    container_name: vernemq
    environment:
      - DOCKER_VERNEMQ_ACCEPT_EULA=yes
      - DOCKER_VERNEMQ_ALLOW_ANONYMOUS=on
      - DOCKER_VERNEMQ_LISTENER__TCP__DEFAULT=0.0.0.0:1883
      - DOCKER_VERNEMQ_LOG__CONSOLE__LEVEL=info
    ports:
      - "1883:1883"
    healthcheck:
      test: ["CMD-SHELL", "timeout 2 bash -c '</dev/tcp/127.0.0.1/1883'"]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 60s

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:19092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:19092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
    ports:
      - "9092:9092"
      - "19092:19092"
    volumes:
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD", "bash", "-lc", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 60s
      
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      DYNAMIC_CONFIG_ENABLED: 'false'
    depends_on:
      kafka:
        condition: service_healthy

  redis:
    image: redis:7-alpine
    container_name: redis-hems
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 3s
      timeout: 2s
      retries: 20
  
  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=admin123
      - DOCKER_INFLUXDB_INIT_ORG=hems
      - DOCKER_INFLUXDB_INIT_BUCKET=hems_timeseries
      # Token de desenvolvimento (use um segredo de verdade em prod)
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=dev-token
    volumes:
      - influxdb_data:/var/lib/influxdb2
    healthcheck:
      test: ["CMD", "influx", "ping", "--host", "http://localhost:8086"]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 30s

  minio:
    image: minio/minio:latest
    container_name: minio
    command: server --console-address ":9001" /data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9000/minio/health/ready >/dev/null || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 20s

  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      set -e;
      mc alias set local http://minio:9000 minioadmin minioadmin;
      mc mb -p local/hems-datalake || true;
      exit 0;
      "

  # =========================================================================================================

  schema-loader:
    build: ./schema-registry
    container_name: schema-loader
    restart: "no"
    environment:
      - SCHEMA_REGISTRY_FS_ROOT=/app
      - REDIS_ADDR=redis:6379
      - SCHEMA_TTL_SECONDS=0
    depends_on:
      redis:
        condition: service_healthy
    entrypoint: ["/app/schema-loader"]

  collector:
    build: ./collector
    container_name: collector
    restart: unless-stopped
    environment:
      - MQTT_BROKER_URL=tcp://vernemq:1883
      - MQTT_CLIENT_ID=hems-collector
      - MQTT_TOPIC=ingestion/telemetry
      - MQTT_QOS=0
      - MQTT_CHANNEL_DEPTH=5000
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=raw-events-topic
      - KAFKA_DLQ_TOPIC=raw-events-dlq
      - KAFKA_TOPIC_PARTITIONS=6
      - KAFKA_DLQ_PARTITIONS=1
      - KAFKA_REPLICATION_FACTOR=1
      - KAFKA_BATCH_SIZE=2000
      - KAFKA_BATCH_BYTES=1048576
      - KAFKA_BATCH_TIMEOUT_MS=5
      - KAFKA_COMPRESSION=snappy
      - KAFKA_REQUIRED_ACKS=one
      - KAFKA_MAX_ATTEMPTS=5
      - PROCESSING_WORKERS=8
      - WORKER_QUEUE_SIZE=10000
      - WORK_QUEUE_STRATEGY=block
      - WORK_QUEUE_ENQ_TIMEOUT_MS=50
      - DISPATCHER_CAPACITY=20000
      - DISPATCHER_MAX_BATCH=2000
      - DISPATCHER_TICK_MS=4
    depends_on:
      vernemq:
        condition: service_healthy
      kafka:
        condition: service_healthy

  validator:
    build: ./validator
    container_name: validator
    restart: unless-stopped
    environment:
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_INPUT_TOPIC=raw-events-topic
      - KAFKA_OUTPUT_TOPIC=validated-events-topic
      - KAFKA_DLQ_TOPIC=validated-events-dlq
      - REDIS_ADDR=redis:6379
      - REDIS_DB=0
      - REDIS_NAMESPACE=schema
      - REDIS_USE_PUBSUB=true
      - REDIS_INVALIDATE_CHANNEL=schemas:invalidate
      - PROCESSING_WORKERS=8
      - ACK_BATCH_SIZE=500
    depends_on:
      collector:
        condition: service_started
      redis:
        condition: service_healthy
      schema-loader:
        condition: service_completed_successfully

  enricher:
    build: ./enricher
    container_name: enricher
    restart: unless-stopped
    environment:
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_INPUT_TOPIC=validated-events-topic
      - KAFKA_OUTPUT_TOPIC=enriched-events-topic
      - KAFKA_DLQ_TOPIC=enriched-events-dlq
      - CONTEXT_STORE_PATH=/app/device-context.json
      - PROCESSING_WORKERS=8
      - ACK_BATCH_SIZE=500
    depends_on:
      validator:
        condition: service_started
      kafka:
        condition: service_healthy

  real-time-loader:
    build: ./real-time-loader
    container_name: real-time-loader
    restart: unless-stopped
    environment:
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_GROUP_ID=real-time-loader
      - KAFKA_INPUT_TOPIC=enriched-events-topic
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_TOKEN=dev-token
      - INFLUX_ORG=hems
      - INFLUX_BUCKET=hems_timeseries
      - PROCESSING_WORKERS=8
      - ACK_BATCH_SIZE=500
      - KAFKA_MIN_BYTES=10000
      - KAFKA_MAX_BYTES=10000000
      - KAFKA_MAX_WAIT_MS=50
      - INFLUX_BATCH_SIZE=5000
      - INFLUX_FLUSH_INTERVAL_MS=100
    depends_on:
      kafka:
        condition: service_healthy
      influxdb:
        condition: service_healthy

  batch-loader:
    build: ./batch-loader
    container_name: batch-loader
    restart: unless-stopped
    environment:
      # ===== Kafka
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_GROUP_ID=batch-loader
      - KAFKA_INPUT_TOPIC=enriched-events-topic
      - KAFKA_MIN_BYTES=10000
      - KAFKA_MAX_BYTES=1000000
      - KAFKA_MAX_WAIT_MS=200
      # ===== Batching (ajuste conforme o volume)
      - BATCH_MAX_RECORDS=100000
      - BATCH_MAX_INTERVAL=2m
      - BATCH_MAX_BYTES=134217728 # 128MB
      # ===== MinIO / S3
      - S3_ENDPOINT=minio:9000
      - S3_ACCESS_KEY=minioadmin
      - S3_SECRET_KEY=minioadmin
      - S3_USE_TLS=false
      - S3_BUCKET=data-lakehouse
      - S3_BASE_PATH=bronze/hems
      # ===== Parquet
      - PARQUET_COMPRESSION=SNAPPY # ou ZSTD/GZIP
    depends_on:
      kafka:
        condition: service_healthy
      enricher:
        condition: service_started
      minio-init:
        condition: service_completed_successfully

volumes:
  kafka_data:
    driver: local
    driver_opts:
      type: none
      device: ./volumes/kafka_data
      o: bind
  influxdb_data:
    driver: local
    driver_opts:
      type: none
      device: ./volumes/influxdb_data
      o: bind
  minio_data:
    driver: local
    driver_opts:
      type: none
      device: ./volumes/minio_data
      o: bind